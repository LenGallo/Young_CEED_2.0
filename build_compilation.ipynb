{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e370421-d2f7-4759-908a-b47e1c487b56",
   "metadata": {},
   "source": [
    "# build_compilation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54acb53-153e-4623-be27-a73a37001046",
   "metadata": {},
   "source": [
    "This notebook iterates through each paleomagnetic record (datasheet) of the vgp database, extracts data which meet user-specified criteria, and appends them to a new dataframe for later processing (to generate an APWP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2daf731b-250b-4616-8cff-9e29f1d27413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pmagpy import ipmag, pmag\n",
    "import scripts.auxiliar as aux\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00c203d-b834-475e-8c2e-5ea52c06ffff",
   "metadata": {},
   "source": [
    "Set the directory from which we will pull the datasheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca35b575-9108-4b9f-b671-a4fece3c27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_vgp = os.getcwd() + '/vgp_database'\n",
    "files_names = aux.get_files_in_directory(data_path_vgp)\n",
    "csv_file_names = [os.path.splitext(os.path.basename(open(file,'r').name))[0] for file in files_names if file.endswith('.csv')] #consider just *csv files\n",
    "paths = [file for file in files_names if file.endswith('.csv')] \n",
    "files = pd.DataFrame({'path': paths, 'name': csv_file_names})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691e5a0-6fd3-4489-aa61-278f543fd1e7",
   "metadata": {},
   "source": [
    "### Set data inclusion criteria\n",
    "Specify the inclusion criteria to be used in the data-selection. If author_selection is set=1, all other criteria will be ignored. Setting values other than 'None' for the remaining criteria allow them to be homogenized across studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064a4b1a-f1d8-4b8d-a2a8-24f1ccb6347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "incl_criteria = {\n",
    "    'author_selection': 1,     # 1 (yes) or 0 (no); if 1, all other criteria will be ignored\n",
    "    'undemagnetized': None,    # None (defaults to author selection) or 'y'  \n",
    "    'sample_count': None,      # None (defaults to author selection) or int: cutoff n (≥ x)\n",
    "    'alpha_95': None,          # None (defaults to author selection) or float: cutoff A95 (≤ x degrees)\n",
    "    'overprints': None,        # None (defaults to author selection) or 'y'  \n",
    "    'remagnetizations': None,  # None (defaults to author selection) or 'y'\n",
    "    'uncertain_struct': None,  # None (defaults to author selection) or 'y'\n",
    "    'rotated': None,           # None (defaults to author selection) or 'y'\n",
    "    'shallowed': None,         # None (defaults to author selection) or 'y' [***can also implement cutoff f-value here if desired***]\n",
    "    'anomalous_dir': None,     # None (defaults to author selection) or float: cutoff distance (in degrees) between vgp and mean (≤ x degrees)\n",
    "    'uncertain_age': None,     # None (defaults to author selection) or float: cutoff age resolution (in Myr) between min and max (≤ x Myr)\n",
    "    'distinct_age': None,      # None (defaults to author selection) or 'y'\n",
    "    'sub-time_units': None,    # None (defaults to author selection) or 'y'\n",
    "    'rock_type': None,         # None (defaults to author selection) or string: 'all' or 'igneous' or 'sedimentary'\n",
    "    'otherwise_rej': None,     # None (defaults to author selection) or 'y'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707c0ea-85c5-4b2d-bd9b-d58397e8452a",
   "metadata": {},
   "source": [
    "Parse the inclusion criteria to numeric codes used in the vgp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf9e54d-5acf-4074-86b0-a4f0c0decacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the numeric codes selected:  []\n"
     ]
    }
   ],
   "source": [
    "criteria_codes = []\n",
    "if incl_criteria['author_selection'] == 1: pass #ignore all other criteria if original selection is to be used\n",
    "elif incl_criteria['author_selection'] == 0:\n",
    "    if incl_criteria['undemagnetized'] == 'y': criteria_codes.append(1)\n",
    "    if incl_criteria['sample_count'] == type(int): criteria_codes.append(2)\n",
    "    if incl_criteria['alpha_95'] == type(float) or incl_criteria['alpha_95'] == type(int): criteria_codes.append(3)\n",
    "    if incl_criteria['overprints'] == 'y': criteria_codes.append(4)\n",
    "    if incl_criteria['remagnetizations'] == 'y': criteria_codes.append(5)\n",
    "    if incl_criteria['uncertain_struct'] == 'y': criteria_codes.append(6)\n",
    "    if incl_criteria['rotated'] == 'y': criteria_codes.append(7)\n",
    "    if incl_criteria['shallowed'] == 'y': criteria_codes.append(8)\n",
    "    if incl_criteria['anomalous_dir'] == type(float) or incl_criteria['anomalous_dir'] == type(int): criteria_codes.append(9)\n",
    "    if incl_criteria['uncertain_age'] == type(float) or incl_criteria['uncertain_age'] == type(int): criteria_codes.append(10)    \n",
    "    if incl_criteria['distinct_age'] == 'y': criteria_codes.append(11)\n",
    "    if incl_criteria['sub-time_units'] == 'y': criteria_codes.append(12)\n",
    "    if incl_criteria['rock_type'] == 'all' or incl_criteria['rock_type'] == 'igneous' or incl_criteria['rock_type'] == 'sedimentary': criteria_codes.append(13)\n",
    "    if incl_criteria['otherwise_rej'] == 'y': criteria_codes.append(14)\n",
    "else:\n",
    "    print ('invalid inclusion criterion selected for author_selection')\n",
    "    \n",
    "print ('the numeric codes selected: ', criteria_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed91afb6-01f3-46dd-a020-1d489cba62e6",
   "metadata": {},
   "source": [
    "### Initialize new compilation dataframes and reference counters\n",
    "We will append the data extracted / recalculated from each datasheet into a new compilation, and so need to initialize new dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de78e1d5-b262-4c80-9e29-1cec56651aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgp_compilation = pd.DataFrame()\n",
    "df_pole_compilation = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507e518-2207-45a1-be31-192175d4290e",
   "metadata": {},
   "source": [
    "Several elements of the vgp database involve internal references between sites of a given datasheet, namely: those belonging to common rotated regions, a sequence of stratigraphically ordered sites, and sites with redundant data (e.g. 2 or more sites from synchronous units). In all cases, this referencing is achieved by way of simple numeric tags which are non-unique between datasheets. In order to preserve these references when we merge datasheets, we need to make each code unique. This is easily achieved with use of counters, which we also initialize here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60383ab0-f5f2-400a-8fcb-157399810d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_cntr = 0    # counter for rotated area references\n",
    "strat_cntr = 0  # counter for stratigraphic group references\n",
    "synch_cntr = 0  # counter for synchronous unit references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b179e747-666f-4dfe-9867-724cd9bd524a",
   "metadata": {},
   "source": [
    "## Example\n",
    "In order to illustrate the workflow, we select an arbitrary single datasheet to process below, before executing the same process on the entire database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5ddee7-5f11-4f0f-8834-3034f8aade70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "0   test\n",
       "1  test2\n",
       "2  test3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f961bc-397a-423d-beb2-e10d1e3df471",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a877e-b588-459f-ae03-3356f65b1a78",
   "metadata": {},
   "source": [
    "### Split study- and site-level data\n",
    "Each datasheet contains both study-level poles and site-level vgps. We split and assign these to separate dataframes and cast types for their constituent series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bef8f1c3-4d34-4957-aa89-41949a5bb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasheet (files, file_idx): \n",
    "    df = pd.read_csv(files['path'][file_idx], skip_blank_lines = False, encoding = \"ISO-8859-1\") #, skip_blank_lines=True\n",
    "    df_list = np.split(df, df[df.isnull().all(1)].index)\n",
    "    df_poles = df_list[0]\n",
    "    df_vgps = df_list[1].dropna(how='all')\n",
    "    df_vgps = df_vgps.rename(columns = df_vgps.iloc[0]).drop(df_vgps.index[0]) # assign the first row as columns for the df_vgps\n",
    "    \n",
    "    #cast columns (using floats everywhere b/c columns with NaNs cannot be cast as ints...can always remove NaNs and recast as int later if needed)\n",
    "    df_poles = df_poles.astype({'pole':float, 'name':str, 'slat':float, 'slon':float, 'N':float, 'dec':float, 'inc':float, 'k':float, 'alpha95':float, \\\n",
    "                                'f_corr': float, 'Plat':float, 'Plon':float, 'K':float, 'A95':float, 'dp':float, 'dm':float, 'mean_age':float, \\\n",
    "                                'min_age':float, '2sig_min':float, 'max_age':float, '2sig_max':float, 'uncer_dist':str, 'rock_typ_1':str, \\\n",
    "                                'rock_typ_2':str, 'rock_typ_3':str, 'R1':int, 'R2.1':float, 'R2.2':float, 'R3':float, 'R4':float, 'R5.1':float, \\\n",
    "                                'R5.2':float, 'R6':float, 'R7':float, 'pmag_ref':str, 'age_ref':str, 'pmag_comments':str, 'age_comments':str})\n",
    "    \n",
    "    df_vgps = df_vgps.astype({'name':str, 'fm./loc.':str, 'slat':float, 'slon':float, 'n':float, 'dec':float, 'inc':float, 'k':float, 'alpha95':float, \\\n",
    "                                'f_corr': float, 'VGP_lat':float, 'VGP_lon':float, 'K':float, 'A95':float, 'dp':float, 'dm':float, 'mean_age':float, \\\n",
    "                                'min_age':float, '2sig_min':float, 'max_age':float, '2sig_max':float, 'uncer_dist':str, 'rock_typ_1':str, \\\n",
    "                                'rock_typ_2':str, 'rock_typ_3':str, 'demag':float, 'struc_cont':float, 'rot_area':float, 'polarity':str, \\\n",
    "                                'strat_group':float, 'ordering':float, 'synch_unit':str, 'in_study_pole':str, 'rej_crit':str, 'pmag_ref':str, \\\n",
    "                                'age_ref':str, 'pmag_comments':str, 'age_comments':str})\n",
    "    \n",
    "    return (df_poles, df_vgps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b793aa-c9f0-4313-959a-cd036da96666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poles, df_vgps = split_datasheet(files, file_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabcf73-742f-463d-a53d-dacbd57bc85d",
   "metadata": {},
   "source": [
    "Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a6157f-d1a1-4dc6-9aff-3f27543c2896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pole</th>\n",
       "      <th>name</th>\n",
       "      <th>slat</th>\n",
       "      <th>slon</th>\n",
       "      <th>N</th>\n",
       "      <th>dec</th>\n",
       "      <th>inc</th>\n",
       "      <th>k</th>\n",
       "      <th>alpha95</th>\n",
       "      <th>f_corr</th>\n",
       "      <th>Plat</th>\n",
       "      <th>Plon</th>\n",
       "      <th>K</th>\n",
       "      <th>A95</th>\n",
       "      <th>dp</th>\n",
       "      <th>dm</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>min_age</th>\n",
       "      <th>2sig_min</th>\n",
       "      <th>max_age</th>\n",
       "      <th>2sig_max</th>\n",
       "      <th>uncer_dist</th>\n",
       "      <th>rock_typ_1</th>\n",
       "      <th>rock_typ_2</th>\n",
       "      <th>rock_typ_3</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2.1</th>\n",
       "      <th>R2.2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5.1</th>\n",
       "      <th>R5.2</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>pmag_ref</th>\n",
       "      <th>age_ref</th>\n",
       "      <th>pmag_comments</th>\n",
       "      <th>age_comments</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Quaternary age rocks; Western Central TMVB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>37.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.7</td>\n",
       "      <td>314.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uniform</td>\n",
       "      <td>igneous</td>\n",
       "      <td>volcanic</td>\n",
       "      <td>mafic to intermediate lavas</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>GTS2020</td>\n",
       "      <td>no field stability tests; structural coherence...</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>late Miocene-Pliocene age rocks; Western Centr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>38.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>265.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uniform</td>\n",
       "      <td>igneous</td>\n",
       "      <td>volcanic</td>\n",
       "      <td>mafic to intermediate lavas</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>GTS2020</td>\n",
       "      <td>no field stability tests; structural coherence...</td>\n",
       "      <td>min age is Pliocene-Quaternary boundary; max a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pole                                               name  slat  slon     N  \\\n",
       "0   1.0         Quaternary age rocks; Western Central TMVB   NaN   NaN  10.0   \n",
       "1   2.0  late Miocene-Pliocene age rocks; Western Centr...   NaN   NaN  33.0   \n",
       "\n",
       "   dec   inc     k  alpha95  f_corr  Plat   Plon     K  A95  dp  dm  mean_age  \\\n",
       "0  2.9  37.5  38.0      7.9     NaN  86.7  314.0  43.0  7.5 NaN NaN       NaN   \n",
       "1  0.6  38.2  22.0      5.4     NaN  88.0  265.5  26.0  5.0 NaN NaN       NaN   \n",
       "\n",
       "   min_age  2sig_min  max_age  2sig_max uncer_dist rock_typ_1 rock_typ_2  \\\n",
       "0     0.00       NaN     2.58       NaN    uniform    igneous   volcanic   \n",
       "1     2.58       NaN    11.20       NaN    uniform    igneous   volcanic   \n",
       "\n",
       "                    rock_typ_3  R1  R2.1  R2.2   R3   R4  R5.1  R5.2  R6   R7  \\\n",
       "0  mafic to intermediate lavas   1   NaN   NaN  1.0  0.0   NaN   NaN NaN  1.0   \n",
       "1  mafic to intermediate lavas   1   NaN   NaN  1.0  0.0   NaN   NaN NaN  1.0   \n",
       "\n",
       "                      pmag_ref  age_ref  \\\n",
       "0  Ruiz-Martínez et al. (2010)  GTS2020   \n",
       "1  Ruiz-Martínez et al. (2010)  GTS2020   \n",
       "\n",
       "                                       pmag_comments  \\\n",
       "0  no field stability tests; structural coherence...   \n",
       "1  no field stability tests; structural coherence...   \n",
       "\n",
       "                                        age_comments  Unnamed: 38  \\\n",
       "0                                                nan          NaN   \n",
       "1  min age is Pliocene-Quaternary boundary; max a...          NaN   \n",
       "\n",
       "   Unnamed: 39  Unnamed: 40  Unnamed: 41  Unnamed: 42  \n",
       "0          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "078f7386-472d-4121-a5ee-bc511c054287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fm./loc.</th>\n",
       "      <th>slat</th>\n",
       "      <th>slon</th>\n",
       "      <th>n</th>\n",
       "      <th>dec</th>\n",
       "      <th>inc</th>\n",
       "      <th>k</th>\n",
       "      <th>alpha95</th>\n",
       "      <th>f_corr</th>\n",
       "      <th>VGP_lat</th>\n",
       "      <th>VGP_lon</th>\n",
       "      <th>K</th>\n",
       "      <th>A95</th>\n",
       "      <th>dp</th>\n",
       "      <th>dm</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>min_age</th>\n",
       "      <th>2sig_min</th>\n",
       "      <th>max_age</th>\n",
       "      <th>2sig_max</th>\n",
       "      <th>uncer_dist</th>\n",
       "      <th>rock_typ_1</th>\n",
       "      <th>rock_typ_2</th>\n",
       "      <th>rock_typ_3</th>\n",
       "      <th>demag</th>\n",
       "      <th>struc_cont</th>\n",
       "      <th>rot_area</th>\n",
       "      <th>polarity</th>\n",
       "      <th>strat_group</th>\n",
       "      <th>ordering</th>\n",
       "      <th>synch_unit</th>\n",
       "      <th>in_study_pole</th>\n",
       "      <th>rej_crit</th>\n",
       "      <th>pmag_ref</th>\n",
       "      <th>age_ref</th>\n",
       "      <th>pmag_comments</th>\n",
       "      <th>age_comments</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mwnHIG</td>\n",
       "      <td>Western sector of TMVB</td>\n",
       "      <td>20.79</td>\n",
       "      <td>-105.48</td>\n",
       "      <td>11.0</td>\n",
       "      <td>343.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.4</td>\n",
       "      <td>140.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.20</td>\n",
       "      <td>9.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>igneous</td>\n",
       "      <td>volcanic</td>\n",
       "      <td>mafic to intermediate lavas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mwrSF</td>\n",
       "      <td>Western sector of TMVB</td>\n",
       "      <td>20.89</td>\n",
       "      <td>-105.41</td>\n",
       "      <td>11.0</td>\n",
       "      <td>190.8</td>\n",
       "      <td>-45.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.10</td>\n",
       "      <td>10.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>igneous</td>\n",
       "      <td>volcanic</td>\n",
       "      <td>mafic to intermediate lavas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>scattered directions</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pwnPLA</td>\n",
       "      <td>Western sector of TMVB</td>\n",
       "      <td>21.35</td>\n",
       "      <td>-105.24</td>\n",
       "      <td>8.0</td>\n",
       "      <td>351.1</td>\n",
       "      <td>31.3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.5</td>\n",
       "      <td>138.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uniform</td>\n",
       "      <td>igneous</td>\n",
       "      <td>volcanic</td>\n",
       "      <td>mafic to intermediate lavas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pwrLIB</td>\n",
       "      <td>Western sector of TMVB</td>\n",
       "      <td>21.58</td>\n",
       "      <td>-105.19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>166.5</td>\n",
       "      <td>-41.1</td>\n",
       "      <td>492.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.4</td>\n",
       "      <td>176.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uniform</td>\n",
       "      <td>igneous</td>\n",
       "      <td>volcanic</td>\n",
       "      <td>mafic to intermediate lavas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pwrJOL</td>\n",
       "      <td>Western sector of TMVB</td>\n",
       "      <td>21.40</td>\n",
       "      <td>-105.18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>49.1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.6</td>\n",
       "      <td>294.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>igneous</td>\n",
       "      <td>volcanic</td>\n",
       "      <td>mafic to intermediate lavas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>Ruiz-Martínez et al. (2010)</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                fm./loc.   slat    slon     n    dec   inc      k  \\\n",
       "4  mwnHIG  Western sector of TMVB  20.79 -105.48  11.0  343.6  24.6   37.0   \n",
       "5   mwrSF  Western sector of TMVB  20.89 -105.41  11.0  190.8 -45.3    2.0   \n",
       "6  pwnPLA  Western sector of TMVB  21.35 -105.24   8.0  351.1  31.3   60.0   \n",
       "7  pwrLIB  Western sector of TMVB  21.58 -105.19  10.0  166.5 -41.1  492.0   \n",
       "8  pwrJOL  Western sector of TMVB  21.40 -105.18   7.0    8.4  49.1   78.0   \n",
       "\n",
       "   alpha95  f_corr  VGP_lat  VGP_lon   K  A95  dp  dm  mean_age  min_age  \\\n",
       "4      6.9     NaN     72.4    140.4 NaN  NaN NaN NaN     10.20     9.40   \n",
       "5     30.5     NaN      NaN      NaN NaN  NaN NaN NaN     11.10    10.90   \n",
       "6      6.4     NaN     80.5    138.4 NaN  NaN NaN NaN       NaN     2.58   \n",
       "7      2.2     NaN     77.4    176.4 NaN  NaN NaN NaN       NaN     2.58   \n",
       "8      6.9     NaN     78.6    294.4 NaN  NaN NaN NaN      3.36     3.19   \n",
       "\n",
       "   2sig_min  max_age  2sig_max uncer_dist rock_typ_1 rock_typ_2  \\\n",
       "4       NaN    11.00       NaN     normal    igneous   volcanic   \n",
       "5       NaN    11.30       NaN     normal    igneous   volcanic   \n",
       "6       NaN     3.50       NaN    uniform    igneous   volcanic   \n",
       "7       NaN     3.50       NaN    uniform    igneous   volcanic   \n",
       "8       NaN     3.53       NaN     normal    igneous   volcanic   \n",
       "\n",
       "                    rock_typ_3  demag  struc_cont  rot_area polarity  \\\n",
       "4  mafic to intermediate lavas    NaN         NaN       NaN      nan   \n",
       "5  mafic to intermediate lavas    NaN         NaN       NaN      nan   \n",
       "6  mafic to intermediate lavas    NaN         NaN       NaN      nan   \n",
       "7  mafic to intermediate lavas    NaN         NaN       NaN      nan   \n",
       "8  mafic to intermediate lavas    NaN         NaN       NaN      nan   \n",
       "\n",
       "   strat_group  ordering synch_unit in_study_pole rej_crit  \\\n",
       "4          0.0       NaN          0             2      nan   \n",
       "5          0.0       NaN          0             0        3   \n",
       "6          0.0       NaN          0             2      nan   \n",
       "7          0.0       NaN          0             2      nan   \n",
       "8          0.0       NaN          0             2      nan   \n",
       "\n",
       "                      pmag_ref                      age_ref  \\\n",
       "4  Ruiz-Martínez et al. (2010)  Ruiz-Martínez et al. (2010)   \n",
       "5  Ruiz-Martínez et al. (2010)  Ruiz-Martínez et al. (2010)   \n",
       "6  Ruiz-Martínez et al. (2010)  Ruiz-Martínez et al. (2010)   \n",
       "7  Ruiz-Martínez et al. (2010)  Ruiz-Martínez et al. (2010)   \n",
       "8  Ruiz-Martínez et al. (2010)  Ruiz-Martínez et al. (2010)   \n",
       "\n",
       "          pmag_comments age_comments  NaN  NaN  NaN  NaN  NaN  \n",
       "4                   nan          nan  NaN  NaN  NaN  NaN  NaN  \n",
       "5  scattered directions          nan  NaN  NaN  NaN  NaN  NaN  \n",
       "6                   nan          nan  NaN  NaN  NaN  NaN  NaN  \n",
       "7                   nan          nan  NaN  NaN  NaN  NaN  NaN  \n",
       "8                   nan          nan  NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vgps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313cafad-4a9e-4059-9bdc-97eaf42a4f70",
   "metadata": {},
   "source": [
    "### Parse data\n",
    "The datasheets mostly report only those data provided in the original publication, so some series will be empty. In some cases these include series which we later need to operate on, so we need to compute these missing series (where possible from other reported data) or dismiss these entries. For this we will utilize several functions from the auxiliary library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af4ab6-c077-4b9f-9619-b2f264403b70",
   "metadata": {},
   "source": [
    "Compute vgps, where absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a431677f-2a5d-40e4-ae1c-e7fdbfd46e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps = aux.get_poles(df_vgps, 'name', 'slat', 'slon', 'dec', 'inc', 'VGP_lat', 'VGP_lon', file_idx, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae78eb0-9b3f-4206-94bb-1652c85dc30f",
   "metadata": {},
   "source": [
    "Cross-check the reported vgps against the dec/inc and slat/slon. Where poles appear to have been inverted, flip back to the correct polarity. Flag any otherwise spurious vgps to be checked against the original report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e9911fc-7741-4bec-b708-a277a5d0a9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgp from site pwrLIB in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pwnPAL in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pwrJAL in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pwrSJG in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pwrFER in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site mcrARE in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pcrCHA in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site mcrFIN in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pcrTRO in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pcrOCO in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site qcrCG in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pcrPEN in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site qcrEST in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site qcrROD in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site qcrCSA in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pcrHUA in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site pcrSOL in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site mcrCAN in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site mcrORD in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "vgp from site mcrAZU in file index 2 appears to be inverted. Flipping back (but perhaps check original reference).\n",
      "***SPURIOUS*** vgp from site pcrTRA in file index 2; reported pole differs from re-calculated by 173 degrees. CHECK against original reference\n"
     ]
    }
   ],
   "source": [
    "df_vgps = aux.xcheck_dirs_poles(df_vgps, 'name', 'slat', 'slon', 'dec', 'inc', 'VGP_lat', 'VGP_lon', file_idx, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fcc5fc-2f49-4a76-9823-50934148836b",
   "metadata": {},
   "source": [
    "Determine the polarity of each entry and create a new series with the data cast into the same (reverse) polarity (which makes life a bit easier later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0f0c5bd-d6e6-4158-a8b1-94513361ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps = aux.go_reverse(df_vgps, 'VGP_lat', 'VGP_lon', 'rev_VGP_lat', 'rev_VGP_lon', rev_mean=[0,-90])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734cd550-3641-417a-9089-640feec367e7",
   "metadata": {},
   "source": [
    "Compute alpha 95s, where absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c5d4b6b-6639-47ff-9173-a3f217f7bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps = aux.get_alpha95s(df_vgps, 'name', 'n', 'alpha95', 'k', file_idx, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f5442b-e449-482c-a2a8-6db4714f9f1d",
   "metadata": {},
   "source": [
    "### Exchange local references for unique ones\n",
    "Exchange the internal references for the rotation areas, strat groups and synchronous units of a given datasheet with database-wide unique IDs using the counters. This ensures the references remain uniquely identifiable after merger of the individual datasheets into a compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f59ae546-82d3-4726-9e0c-c2ec1cd3b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_uniq_ids (df, rot_cntr, strat_cntr, synch_cntr):  # exchange local references for unique codes\n",
    "    \n",
    "    # assign unique ids to rotated areas and stratigraphic groups\n",
    "    df.rot_area.fillna(value='0')\n",
    "    df['rot_area'] = df.apply(lambda row: row.rot_area + rot_cntr if not row.rot_area == 0 else row.rot_area, axis=1)\n",
    "    df.strat_group.fillna(value='0')\n",
    "    df['strat_group'] = df.apply(lambda row: row.strat_group + strat_cntr if not row.strat_group == 0 else row.strat_group, axis=1)\n",
    "    \n",
    "    # update counters with new max values from local lists\n",
    "    rot_cntr = df['rot_area'].max()\n",
    "    strat_cntr = df['strat_group'].max()\n",
    "\n",
    "    # assign unique ids to synchronous units (note that some entries have an 'M' prefix that designates them as a local mean)\n",
    "    df.synch_unit.fillna(value='0')\n",
    "    df.synch_unit = df.synch_unit.astype('str') # ensure that synch_unit entries are strings\n",
    "    df['synch_unit'] = df.apply(lambda row: ' '.join(re.findall(\"[a-zA-Z]+\", row.synch_unit)) + str(int(''.join(filter(str.isdigit, row.synch_unit))) \\\n",
    "                                                    + synch_cntr) if not row.synch_unit == '0' else row.synch_unit, axis = 1)\n",
    "    \n",
    "    #update counter with new max value\n",
    "    synch_cntr = pd.to_numeric(df['synch_unit'], 'coerce').max()\n",
    "\n",
    "    return (df, rot_cntr, strat_cntr, synch_cntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "242e5a34-0684-4eac-9633-6da0198e12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps, rot_cntr, strat_cntr, synch_cntr = assign_uniq_ids(df_vgps, rot_cntr, strat_cntr, synch_cntr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c2270-7bfe-4cb5-9107-c71082862571",
   "metadata": {},
   "source": [
    "## Filter data\n",
    "Now evaluate the entries against the specified inclusion criteria. We start by filtering any entries that don't have the right inclusion codes and those which fail any specified n, alpha95, age uncertainty and/or rock type criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f0b8410-c908-48b1-a954-a66929fd924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_filter (df, incl_criteria, criteria_codes):\n",
    "    \n",
    "    df['rej_crit'] = df['rej_crit'].fillna(0) # replace NaNs in this column with 0's\n",
    "    \n",
    "    # make a new temp. series to flag entries which do / don't pass the basic inclusion criteria according to rej_crit codes\n",
    "    df['keep'] = df.apply(lambda row: True if row.in_study_pole != 0 or all(crit in criteria_codes for crit in [int(i) for i in str(row.rej_crit).split(',')]) \\\n",
    "                                else False, axis=1)\n",
    "    \n",
    "    # reject any entries with too small sample count\n",
    "    if 2 in criteria_codes:\n",
    "        df['keep'] = df.apply(lambda row: False if row.n < incl_criteria['sample_count'] else row.keep, axis=1)\n",
    "\n",
    "    # reject any entries with too large alpha 95\n",
    "    if 3 in criteria_codes:  \n",
    "        df['keep'] = df.apply(lambda row: False if row.alpha95 > incl_criteria['alpha_95'] else row.keep, axis=1)\n",
    "\n",
    "    # reject vgps with too large age uncertainty (as determined by diff b/w min and max)\n",
    "    if 10 in criteria_codes:\n",
    "        df['keep'] = df.apply(lambda row: False if (row.max_age - row.min_age) > incl_criteria['uncertain_age'] else row.keep, axis=1)\n",
    "\n",
    "    # reject vgps with wrong rock type\n",
    "    if 13 in criteria_codes: \n",
    "        if incl_criteria['rock_type'] == 'all': pass\n",
    "        else: df['keep'] = df.apply(lambda row: False if row.rock_typ_1 != incl_criteria['rock_type'] else row.keep, axis=1)\n",
    "            \n",
    "    df.drop(df[df.keep == False].index, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80055c0e-66cf-4610-aa27-e8ac5ab51dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps = init_filter(df_vgps, incl_criteria, criteria_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3e788-0dcf-4f41-ae95-a877431a43d2",
   "metadata": {},
   "source": [
    "We still need to find and reject any anomalous vgps (if such criteria were specified above). However, in order to evaluate this, we need a provisional paleopole. Before we compute that we need to remove any vgps with distinct ages (since they shouldn't contribute to the paleopole calculation). These temporally distinctive entries can be sent to the main compilation (as they have otherwise passed the basic inclusion criteria above) and deleted from the working dataframe here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e7a91f9-ea74-4e02-b6a4-5f683fb5c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_age_distinct (df, df_vgp_compilation, criteria_codes):\n",
    "\n",
    "    # check if any entries with distinct age and flag with a NaN in the 'keep' column\n",
    "    if 11 in criteria_codes:\n",
    "        df['keep'] = df.apply(lambda row: np.nan if (row.keep == True and 11 in [int(i) for i in str(row.rej_crit).split(',')]) else row.keep, axis=1) \n",
    "\n",
    "        #pass these distinct age vgps to the vgp compilation\n",
    "        df_distinct = df[df['keep'] == np.nan]\n",
    "        df_vgp_compilation = pd.concat([df_vgp_compilation, df_distinct], axis=0)\n",
    "\n",
    "        #drop the distinct vgps from the selected list\n",
    "        df.drop(df_distinct.index, axis=0, inplace=True)\n",
    "    \n",
    "    return (df, df_vgp_compilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2febf231-38d7-4dac-933c-4a5d888eff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps, df_vgp_compilation = strip_age_distinct(df_vgps, df_vgp_compilation, criteria_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb98862-df94-4bee-af19-689c9eb9db15",
   "metadata": {},
   "source": [
    "## Compute provisional paleopole\n",
    "Now we can compute a provisional paleopole and check for 'anomalous' vgps (as user-defined). To do this rigorously presents a potential recursive headache because we should first pre-average any synchronous units, but some of these could include vgps susequently recognized as 'anomalous', requiring calculation of a new provisional pole, etc. Here we instead adopt a simple approximation: defaulting to the subset of selected data which the original authors retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72164296-3ea7-4773-a054-83c06b9618db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_anomalous (df, criteria_codes):\n",
    "\n",
    "    if 9 in criteria_codes: \n",
    "        \n",
    "        #isolate the entries to be used for provisional paleopole calculation\n",
    "        df_prov = df[(df['in_study_pole'] != 0) & (df['keep'] == True)]\n",
    "\n",
    "        #calculate provisional paleopole\n",
    "        ppole = ipmag.fisher_mean(dec = df_prov['rev_VGP_lon'].tolist(), inc = df_prov['rev_VGP_lat'].tolist())\n",
    "\n",
    "        #identify anomalous vgps according to the specification above\n",
    "        df['keep'] = df.apply(lambda row: False if (pmag.angle([row.rev_VGP_lon, row.rev_VGP_lat], [ppole['dec'], ppole['inc']]) \\\n",
    "                                                              > incl_criteria['anomalous_dir']) else row.keep, axis=1)\n",
    "\n",
    "        #drop anomalous entries\n",
    "        df.drop(df[df.keep == False].index, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0449dc83-6c15-4b31-bff2-63ed91825438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps = strip_anomalous(df_vgps, criteria_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77913401-1144-4895-afb2-8f4243e3b860",
   "metadata": {},
   "source": [
    "### Remove sparse time_units collections\n",
    "After filtering there may be some synchronous unit collections with too few entries to merit passing them onward as individual entries. In these cases, we can adopt any existing reported mean and discard the individual entries. Where there exists a sufficient number of individual entries we can pass them on and omit the reported mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "352468ec-cedb-4e84-a71f-804762b482f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_sparse_time_units (df, incl_criteria):\n",
    "\n",
    "    # first specify an n-specific cutoff value to decide whether to recalculate mean or retain the reported one.\n",
    "    min_site_count = 3\n",
    "    if incl_criteria['sample_count'] != None and incl_criteria['sample_count'].isdigit():\n",
    "        if incl_criteria['sampl_count'] > min_site_count: min_site_count = int(incl_criteria['sampl_count'])\n",
    "            \n",
    "    # extract synchronous units from selected list and split into groups\n",
    "    df['keep'] = df.apply(lambda row: False if row.synch_unit != '0' else row.keep, axis=1)\n",
    "    df_redundant = df[df['synch_unit'] != '0']\n",
    "    synch_units = df_redundant.groupby(['synch_unit'])\n",
    "    \n",
    "    # collect means into a list to make them easy to locate\n",
    "    means = [x for x in synch_units.groups if x.isdigit() == False]\n",
    "\n",
    "    # check the number of sites for each group\n",
    "    for key, group in synch_units:\n",
    "        if key.isdigit():    # ignore means\n",
    "            \n",
    "            if len(group) > min_site_count:   # if number of sites is sufficient, keep all individual sites\n",
    "                df.loc[group.index.tolist(), 'keep'] = True\n",
    "\n",
    "            elif ('M'+str(key)) in means:     # if number of sites is too low and mean is reported, keep mean\n",
    "                mean_ent = synch_units.get_group('M'+str(key))\n",
    "                df.loc[mean_ent.index.tolist(), 'keep'] = True\n",
    "                df.loc[mean_ent.index.tolist(), 'synch_unit'] = '0' # set time_unit to 0 as there is now only 1 entry\n",
    "\n",
    "            else:      # if number of sites is too low and no mean is reported, use site with smaller alpha95 (or higher n)\n",
    "                df.loc[group['alpha95'].idxmin(), 'keep'] = True\n",
    "                ### alternatively: group['n'].idxmax()\n",
    "                df.loc[group['alpha95'].idxmin(), 'synch_unit'] = '0'  # set time_unit to 0 as there is now only 1 entry\n",
    "                \n",
    "    #drop discarded entries\n",
    "    df.drop(df[df.keep == False].index, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76d67696-8094-4526-b995-2f507f0fe8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps = strip_sparse_time_units(df_vgps, incl_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cbcb02-c3fd-455f-9bdd-0544623991fe",
   "metadata": {},
   "source": [
    "## Append filtered vgps to compilation\n",
    "Pass the final selected entries to the vgp compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b473666d-1050-4605-a6d4-f689ada6c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgp_compilation = pd.concat([df_vgp_compilation, df_vgps], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fedeb9-a5d5-4dcb-8b2a-88f513825cbd",
   "metadata": {},
   "source": [
    "## Final paleopole recalculation\n",
    "Finally, recalculate the paleopole based on only the filtered set of vgp data, and after pre-averaging any synchronous units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a33374e-b750-4c06-896f-3367cef66115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_synch_units (df): # pre-average any synchronous units\n",
    "    \n",
    "    df['keep'] = df.apply(lambda row: False if row.synch_unit != '0' else row.keep, axis=1)\n",
    "    df_redundant = df[df['synch_unit'] != '0']\n",
    "    synch_units = df_redundant.groupby(['synch_unit'])\n",
    "    \n",
    "    for key, group in synch_units:\n",
    "        mean_age = group['mean_age'].mean(axis=0) # get mean age from among time_unit sites *** NOTE THIS DOESN'T COLLECT / PASS ON UNCERTAINTIES ***\n",
    "        \n",
    "        vgp = ipmag.fisher_mean(dec = group['rev_VGP_lon'].tolist(), inc = group['rev_VGP_lat'].tolist()) # compute mean vgp from among time_units\n",
    "        \n",
    "        df.append({'VGP_lon': vgp['dec'], 'rev_VGP_lon': vgp['dec'], 'VGP_lat': vgp['inc'], 'rev_VGP_lat': vgp['inc'],\n",
    "                   'A95': vgp['alpha95'], 'mean_age': mean_age, 'keep': True}, ignore_index=True)    # other entries could be added but aren't presently needed\n",
    "        \n",
    "    #drop discarded entries\n",
    "    df.drop(df[df.keep == False].index, inplace=True)\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b12bd674-3554-4d70-b076-5866c525f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgps = average_synch_units(df_vgps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aca8e1-ccd8-494a-b7f1-51fcddff31b7",
   "metadata": {},
   "source": [
    "Now compute the final paleopole, determine its corresponding age, and append it to the re-calculated paleopole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5efdd2bb-5a3b-4dff-b5ff-fb48503cfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pole_data (df):\n",
    "\n",
    "    pole = ipmag.fisher_mean(dec = df['rev_VGP_lon'].tolist(), inc = df['rev_VGP_lat'].tolist())\n",
    "    mean_site = ipmag.fisher_mean(dec = df['slon'].tolist(), inc = df['slat'].tolist())\n",
    "    \n",
    "    mean_age = df['mean_age'].mean(axis=0) # get mean pole age  *** NOTE THIS DOESN'T COLLECT / PASS ON UNCERTAINTIES ***\n",
    "    \n",
    "    recomputed_pole_data = {'slat': mean_site['inc'], 'slon': mean_site['dec'], 'N': pole['n'], 'Plat': pole['inc'], 'Plon': pole['dec'], \\\n",
    "                 'K': pole['k'], 'A95': pole['alpha95'], 'mean_age': mean_age}\n",
    "\n",
    "    return recomputed_pole_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5237492e-974c-42cc-bf5c-095a6a15935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pole_compilation = pd.DataFrame(data=None, columns=df_poles.columns) # re-initialized in order to copy over column names\n",
    "recomputed_pole_data = get_pole_data(df_vgps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f81855f-ad92-49e3-865d-c49766980e65",
   "metadata": {},
   "source": [
    "# Execute on entire database\n",
    "Having demonstrated the workflow on an example datasheet, we now execute it on the entire dataset, cycling through all the datasheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdb3a50f-9900-46c8-8128-e70037edb0d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Only a column name can be used for the key in a dtype mappings argument.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-341a2f74134a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# import data and assign to dataframes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdf_poles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_vgps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_datasheet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# parse data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-93e690d5dd56>\u001b[0m in \u001b[0;36msplit_datasheet\u001b[1;34m(files, file_idx)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#cast columns (using floats everywhere b/c columns with NaNs cannot be cast as ints...can always remove NaNs and recast as int later if needed)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     df_poles = df_poles.astype({'pole':float, 'name':str, 'slat':float, 'slon':float, 'N':float, 'dec':float, 'inc':float, 'k':float, 'alpha95':float, \\\n\u001b[0m\u001b[0;32m     10\u001b[0m                                 \u001b[1;34m'f_corr'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Plat'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Plon'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'K'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'A95'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dp'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dm'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mean_age'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                 \u001b[1;34m'min_age'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2sig_min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_age'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2sig_max'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'uncer_dist'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rock_typ_1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pmagpy_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5852\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5853\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5854\u001b[1;33m                     raise KeyError(\n\u001b[0m\u001b[0;32m   5855\u001b[0m                         \u001b[1;34m\"Only a column name can be used for the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5856\u001b[0m                         \u001b[1;34m\"key in a dtype mappings argument.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Only a column name can be used for the key in a dtype mappings argument.'"
     ]
    }
   ],
   "source": [
    "# reset initializations\n",
    "df_vgp_compilation = pd.DataFrame()\n",
    "df_pole_compilation = pd.DataFrame()\n",
    "rot_cntr = 0\n",
    "strat_cntr = 0\n",
    "synch_cntr = 0\n",
    "\n",
    "for i in files.index:   # cycle over each file in database\n",
    "    \n",
    "    # import data and assign to dataframes\n",
    "    df_poles, df_vgps = split_datasheet(files, i)\n",
    "    \n",
    "    # parse data\n",
    "    df_vgps = aux.get_poles(df_vgps, 'name', 'slat', 'slon', 'dec', 'inc', 'VGP_lat', 'VGP_lon', file_idx, verbose=True)\n",
    "    df_vgps = aux.xcheck_dirs_poles(df_vgps, 'name', 'slat', 'slon', 'dec', 'inc', 'VGP_lat', 'VGP_lon', file_idx, verbose=True)\n",
    "    df_vgps = aux.go_reverse(df_vgps, 'VGP_lat', 'VGP_lon', 'rev_VGP_lat', 'rev_VGP_lon', rev_mean=[0,-90])\n",
    "    df_vgps = aux.get_alpha95s(df_vgps, 'name', 'n', 'alpha95', 'k', file_idx, verbose=True)\n",
    "\n",
    "    # exchange local references for unique ids\n",
    "    df_vgps, rot_cntr, strat_cntr, synch_cntr = assign_uniq_ids(df_vgps, rot_cntr, strat_cntr, synch_cntr)\n",
    "    \n",
    "    # filter data\n",
    "    df_vgps = init_filter(df_vgps, incl_criteria, criteria_codes)\n",
    "    df_vgps, df_vgp_compilation = strip_age_distinct(df_vgps, df_vgp_compilation, criteria_codes)\n",
    "    df_vgps = strip_anomalous(df_vgps, criteria_codes)\n",
    "    df_vgps = strip_sparse_time_units(df_vgps, incl_criteria)\n",
    "\n",
    "    # append filtered vgps to compilation\n",
    "    df_vgp_compilation = pd.concat([df_vgp_compilation, df_vgps], axis=0)\n",
    "    \n",
    "    # re-calculate study-level pole\n",
    "    df_vgps = average_synch_units(df_vgps)\n",
    "    recomputed_pole_data = get_pole_data(df_vgps)\n",
    "    \n",
    "    # append new pole entry to compilation\n",
    "    if i == 0: df_pole_compilation = pd.DataFrame(data=None, columns=df_poles.columns)\n",
    "    df_pole_compilation = df_pole_compilation.append(recomputed_pole_data, ignore_index=True)\n",
    "    \n",
    "# write out compilation\n",
    "out_dir = data_path_vgp + '/compilations/'\n",
    "df_vgp_compilation.to_csv(out_dir + 'vgps.csv', index=False)\n",
    "df_pole_compilation.to_csv(out_dir + 'poles.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
